{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuy17iHABf/9UlgUrIeZUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdithyaLakshmi23/assignmentzeotap/blob/main/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**task1**"
      ],
      "metadata": {
        "id": "1KjtSX4IQvoz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHz285ztNmVz"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv(\"Customers.csv\")\n",
        "products = pd.read_csv(\"Products.csv\")\n",
        "transactions = pd.read_csv(\"Transactions.csv\")\n",
        "\n",
        "# Displaying data info and the first few rows for each dataset\n",
        "print(\"Customers Dataset Info:\")\n",
        "print(customers.info())\n",
        "print(customers.head(), \"\\n\")\n",
        "\n",
        "print(\"Products Dataset Info:\")\n",
        "print(products.info())\n",
        "print(products.head(), \"\\n\")\n",
        "\n",
        "print(\"Transactions Dataset Info:\")\n",
        "print(transactions.info())\n",
        "print(transactions.head(), \"\\n\")\n",
        "\n",
        "# Missing values check\n",
        "print(\"Missing values in Customers:\", customers.isnull().sum())\n",
        "print(\"Missing values in Products:\", products.isnull().sum())\n",
        "print(\"Missing values in Transactions:\", transactions.isnull().sum())\n",
        "\n",
        "# Descriptive statistics\n",
        "print(\"Transactions Descriptive Statistics:\")\n",
        "print(transactions.describe())\n",
        "\n",
        "# EDA on Customers\n",
        "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
        "customer_region_count = customers['Region'].value_counts()\n",
        "print(\"Customer count by region:\\n\", customer_region_count)\n",
        "\n",
        "# Visualization: Customer distribution by region\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=customer_region_count.index, y=customer_region_count.values)\n",
        "plt.title(\"Customer Distribution by Region\")\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Number of Customers\")\n",
        "plt.show()\n",
        "\n",
        "# EDA on Products\n",
        "product_category_count = products['Category'].value_counts()\n",
        "print(\"Product count by category:\\n\", product_category_count)\n",
        "\n",
        "# Visualization: Product distribution by category\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=product_category_count.index, y=product_category_count.values)\n",
        "plt.title(\"Product Distribution by Category\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Number of Products\")\n",
        "plt.show()\n",
        "\n",
        "# EDA on Transactions\n",
        "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
        "transactions['YearMonth'] = transactions['TransactionDate'].dt.to_period('M')\n",
        "\n",
        "# Total sales over time\n",
        "sales_over_time = transactions.groupby('YearMonth')['TotalValue'].sum()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sales_over_time.plot(kind='line', marker='o')\n",
        "plt.title(\"Total Sales Over Time\")\n",
        "plt.xlabel(\"Year-Month\")\n",
        "plt.ylabel(\"Total Sales (USD)\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Top 5 products by total sales\n",
        "top_products = transactions.groupby('ProductID')['TotalValue'].sum().nlargest(5)\n",
        "top_product_names = products.loc[products['ProductID'].isin(top_products.index), ['ProductID', 'ProductName']]\n",
        "\n",
        "print(\"Top 5 Products by Total Sales:\")\n",
        "print(pd.merge(top_products.reset_index(), top_product_names, on='ProductID'))\n",
        "\n",
        "# Transactions by region\n",
        "transactions_customers = transactions.merge(customers, on='CustomerID')\n",
        "region_sales = transactions_customers.groupby('Region')['TotalValue'].sum()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=region_sales.index, y=region_sales.values)\n",
        "plt.title(\"Total Sales by Region\")\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Total Sales (USD)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK2**"
      ],
      "metadata": {
        "id": "GpKe2r5EQ2po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv(\"Customers.csv\")\n",
        "products = pd.read_csv(\"Products.csv\")\n",
        "transactions = pd.read_csv(\"Transactions.csv\")\n",
        "\n",
        "# Data Preparation\n",
        "# Merge transactions with customer and product data\n",
        "data = transactions.merge(customers, on=\"CustomerID\").merge(products, on=\"ProductID\")\n",
        "\n",
        "# Feature Engineering\n",
        "# Create customer-level aggregated features\n",
        "customer_features = data.groupby(\"CustomerID\").agg(\n",
        "    total_spent=(\"TotalValue\", \"sum\"),\n",
        "    avg_spent=(\"TotalValue\", \"mean\"),\n",
        "    num_transactions=(\"TransactionID\", \"count\")\n",
        ").reset_index()\n",
        "\n",
        "# One-hot encode region and product categories\n",
        "customer_region = pd.get_dummies(customers.set_index(\"CustomerID\")[\"Region\"], prefix=\"Region\")\n",
        "product_categories = pd.get_dummies(data.set_index(\"CustomerID\")[\"Category\"], prefix=\"Category\")\n",
        "customer_features = customer_features.set_index(\"CustomerID\").join(customer_region).join(product_categories)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(customer_features)\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "similarity_matrix = cosine_similarity(scaled_features)\n",
        "similarity_df = pd.DataFrame(similarity_matrix, index=customer_features.index, columns=customer_features.index)\n",
        "\n",
        "# Generate Recommendations\n",
        "recommendations = {}\n",
        "for customer in customers[\"CustomerID\"][:20]:\n",
        "    similar_customers = (\n",
        "        similarity_df[customer]\n",
        "        .sort_values(ascending=False)[1:4]  # Exclude the customer themselves\n",
        "        .reset_index()\n",
        "    )\n",
        "    similar_customers.columns = [\"cust_id\", \"score\"]\n",
        "    recommendations[customer] = similar_customers.values.tolist()\n",
        "\n",
        "# Save recommendations to Lookalike.csv\n",
        "recommendations_df = pd.DataFrame(\n",
        "    [{\"cust_id\": k, \"similar_customers\": v} for k, v in recommendations.items()]\n",
        ")\n",
        "recommendations_df.to_csv(\"Lookalike.csv\", index=False)\n",
        "\n",
        "print(\"Lookalike.csv has been generated with top 3 recommendations for C0001â€“C0020.\")\n"
      ],
      "metadata": {
        "id": "4Zuo5AxaQ7dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK3**"
      ],
      "metadata": {
        "id": "DNf1lPo5R-Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv(\"Customers.csv\")\n",
        "transactions = pd.read_csv(\"Transactions.csv\")\n",
        "\n",
        "# Merge datasets\n",
        "transactions_agg = transactions.groupby(\"CustomerID\").agg(\n",
        "    total_spent=(\"TotalValue\", \"sum\"),\n",
        "    avg_spent=(\"TotalValue\", \"mean\"),\n",
        "    num_transactions=(\"TransactionID\", \"count\")\n",
        ").reset_index()\n",
        "data = customers.merge(transactions_agg, on=\"CustomerID\", how=\"left\")\n",
        "\n",
        "# Fill missing values (if any customers have no transactions)\n",
        "data.fillna(0, inplace=True)\n",
        "\n",
        "# Encode region as one-hot\n",
        "data = pd.get_dummies(data, columns=[\"Region\"], drop_first=True)\n",
        "\n",
        "# Drop non-numeric columns for clustering\n",
        "data_numeric = data.drop(columns=[\"CustomerID\", \"CustomerName\", \"SignupDate\"])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_numeric)\n",
        "\n",
        "# Clustering using K-Means\n",
        "db_scores = []\n",
        "silhouette_scores = []\n",
        "cluster_range = range(2, 11)\n",
        "\n",
        "for k in cluster_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    clusters = kmeans.fit_predict(data_scaled)\n",
        "\n",
        "    # Calculate Davies-Bouldin Index and Silhouette Score\n",
        "    db_index = davies_bouldin_score(data_scaled, clusters)\n",
        "    silhouette_avg = silhouette_score(data_scaled, clusters)\n",
        "\n",
        "    db_scores.append(db_index)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Optimal number of clusters\n",
        "optimal_k = cluster_range[np.argmin(db_scores)]\n",
        "print(f\"Optimal Number of Clusters (based on DB Index): {optimal_k}\")\n",
        "\n",
        "# Fit K-Means with optimal clusters\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "data[\"Cluster\"] = kmeans.fit_predict(data_scaled)\n",
        "\n",
        "# Visualize Clusters (2D scatter plot using first 2 features)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "    x=data_scaled[:, 0], y=data_scaled[:, 1], hue=data[\"Cluster\"], palette=\"viridis\", s=50\n",
        ")\n",
        "plt.title(\"Customer Segments\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluate Clusters\n",
        "print(f\"Davies-Bouldin Index: {min(db_scores):.4f}\")\n",
        "print(f\"Silhouette Score: {max(silhouette_scores):.4f}\")\n",
        "\n",
        "# Save results\n",
        "data[[\"CustomerID\", \"Cluster\"]].to_csv(\"Customer_Segments.csv\", index=False)\n",
        "print(\"Customer_Segments.csv has been saved.\")\n"
      ],
      "metadata": {
        "id": "D-HVE1hDSCOq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}